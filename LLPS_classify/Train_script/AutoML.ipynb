{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML\n",
    "基于[Autogluon](https://auto.gluon.ai/stable/index.html) 自动机器学习框架快速寻找最优的机器学习模型用于识别LLPS相关的蛋白\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "Embed = 'ESM'\n",
    "\n",
    "DATA_PATH = '../dataset/dataset2.0/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_esm_embed(csv_file,embed_type):\n",
    "    EMBED_PATH = DATA_PATH+embed_type+'_embed/'\n",
    "    EMB_LAYER = 33\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    Embed_PATH = EMBED_PATH+csv_file.split('.')[0]\n",
    "    data_df =  pd.read_csv(DATA_PATH+csv_file)\n",
    "    for index, row in data_df.iterrows():\n",
    "        id = row['id']\n",
    "        label = row['label']\n",
    "\n",
    "        fn = f'{Embed_PATH}/{id}.pt'\n",
    "        embs = torch.load(fn)\n",
    "        \n",
    "        Xs.append(embs['mean_representations'][EMB_LAYER])\n",
    "        ys.append(label)\n",
    "    Xs = torch.stack(Xs, dim=0).numpy()\n",
    "    print('load {} esm embedding'.format(csv_file))\n",
    "    print(len(ys))\n",
    "    print(Xs.shape)\n",
    "    return Xs,ys\n",
    "\n",
    "def load_embed(csv_file,embed_type):\n",
    "    EMBED_PATH = DATA_PATH+embed_type+'_embed/'\n",
    "    Embed_PATH = EMBED_PATH+csv_file.split('.')[0]+'_embeds.npy'\n",
    "    data_df =  pd.read_csv(DATA_PATH+csv_file)\n",
    "    ys = data_df['label']\n",
    "    Xs = np.load(Embed_PATH)\n",
    "    print('load {} {}_embed embedding from {}'.format(csv_file,embed_type,Embed_PATH))\n",
    "    print(len(ys))\n",
    "    print(Xs.shape)\n",
    "    return Xs,ys\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(csv_file,embed= 'ESM'):\n",
    "    if embed=='ESM' or 'ESM2_15b':Xs,ys = load_esm_embed(csv_file,embed)\n",
    "    else:Xs,ys = load_embed(csv_file,embed)\n",
    "    return Xs,ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dataset(embed='ESM'):\n",
    "\n",
    "    positive_data = 'positive_train_422.csv'\n",
    "    negative_data = 'negative_train_3307.csv'\n",
    "    Xs_p,ys_p = embedding(positive_data,embed)\n",
    "    Xs_n,ys_n = embedding(negative_data,embed)\n",
    "    p_df = pd.DataFrame(Xs_p)\n",
    "    p_df['label'] = list(ys_p)\n",
    "    n_df = pd.DataFrame(Xs_n)\n",
    "    n_df['label'] = list(ys_n)\n",
    "    return p_df,n_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load positive_train_422.csv esm embedding\n",
      "422\n",
      "(422, 1280)\n",
      "load negative_train_3307.csv esm embedding\n",
      "3307\n",
      "(3307, 1280)\n"
     ]
    }
   ],
   "source": [
    "p_df,n_df = Create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对数据不均衡的问题\n",
    "### 策略一：过采样（Oversampling）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset,TabularPredictor\n",
    "def AutoML(samlpe = None):\n",
    "    # embed_types = ['ESM','ProtBert_bfd','ProtBert','T5','UniRep','ESM_finetune']\n",
    "    embed_types = ['T5']\n",
    "    if samlpe == 'Oversampling':\n",
    "        for embed in embed_types:\n",
    "            p_df,n_df = Create_dataset(embed)\n",
    "            # p_df = pd.concat([p_df]*8)\n",
    "            p_df = pd.concat([p_df])\n",
    "            df = pd.concat([p_df,n_df])\n",
    "            df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "            df = TabularDataset(df)\n",
    "            TabularPredictor(label=\"label\",path='AutoML_{}_Oversampling'.format(embed)).fit(df,num_bag_folds=10)\n",
    "    elif samlpe == None:\n",
    "        for embed in embed_types:\n",
    "            p_df,n_df = Create_dataset(embed)\n",
    "            p_df = pd.concat([p_df])\n",
    "            df = pd.concat([p_df,n_df])\n",
    "            df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "            df = TabularDataset(df)\n",
    "            # TabularPredictor(label=\"label\",path='AutoML_result_0613-1/AutoML_{}'.format(embed)).fit(df,num_bag_folds=5)\n",
    "            TabularPredictor(label=\"label\",path='AutoML_result_12-5/AutoML_{}'.format(embed)).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load positive_train_422.csv esm embedding\n",
      "422\n",
      "(422, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutoML_result_07-5/AutoML_ESM2_15b/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #78-Ubuntu SMP Tue Apr 18 09:00:29 UTC 2023\n",
      "Train Data Rows:    3729\n",
      "Train Data Columns: 1280\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    261145.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 19.09 MB (0.0% of available memory)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load negative_train_3307.csv esm embedding\n",
      "3307\n",
      "(3307, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1280 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1280 | ['0', '1', '2', '3', '4', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t1280 features in original data used to generate 1280 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 19.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.13408420488066505, Train Rows: 3229, Val Rows: 500\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.892\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.894\t = Validation score   (accuracy)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.92\t = Validation score   (accuracy)\n",
      "\t3.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.918\t = Validation score   (accuracy)\n",
      "\t3.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.906\t = Validation score   (accuracy)\n",
      "\t1.63s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.908\t = Validation score   (accuracy)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.922\t = Validation score   (accuracy)\n",
      "\t21.28s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.902\t = Validation score   (accuracy)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.906\t = Validation score   (accuracy)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.918\t = Validation score   (accuracy)\n",
      "\t5.75s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.914\t = Validation score   (accuracy)\n",
      "\t10.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.92\t = Validation score   (accuracy)\n",
      "\t4.77s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.914\t = Validation score   (accuracy)\n",
      "\t10.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.922\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 69.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoML_result_07-5/AutoML_ESM2_15b/\")\n"
     ]
    }
   ],
   "source": [
    "AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
