{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset,TabularPredictor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "DATA_PATH = '../dataset/dataset2.0/'\n",
    "\n",
    "def load_esm_embed(csv_file,embed_type):\n",
    "    EMBED_PATH = DATA_PATH+embed_type+'_embed/'\n",
    "    EMB_LAYER = 33\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    Embed_PATH = EMBED_PATH+csv_file.split('.')[0]\n",
    "    data_df =  pd.read_csv(DATA_PATH+csv_file)\n",
    "    for index, row in data_df.iterrows():\n",
    "        id = row['id']\n",
    "        label = row['label']\n",
    "\n",
    "        fn = f'{Embed_PATH}/{id}.pt'\n",
    "        embs = torch.load(fn)\n",
    "        \n",
    "        Xs.append(embs['mean_representations'][EMB_LAYER])\n",
    "        ys.append(label)\n",
    "    Xs = torch.stack(Xs, dim=0).numpy()\n",
    "    print('load {} esm embedding'.format(csv_file))\n",
    "    print(len(ys))\n",
    "    print(Xs.shape)\n",
    "    return Xs,ys\n",
    "\n",
    "def load_embed(csv_file,embed_type):\n",
    "    EMBED_PATH = DATA_PATH+embed_type+'_embed/'\n",
    "    Embed_PATH = EMBED_PATH+csv_file.split('.')[0]+'_embeds.npy'\n",
    "    data_df =  pd.read_csv(DATA_PATH+csv_file)\n",
    "    ys = data_df['label']\n",
    "    Xs = np.load(Embed_PATH)\n",
    "    print('load {} {}_embed embedding from {}'.format(csv_file,embed_type,Embed_PATH))\n",
    "    print(len(ys))\n",
    "    print(Xs.shape)\n",
    "    return Xs,ys\n",
    "\n",
    "def embedding(csv_file,embed= None):\n",
    "    if embed=='ESM':Xs,ys = load_esm_embed(csv_file,embed)\n",
    "    else:Xs,ys = load_embed(csv_file,embed)\n",
    "    return Xs,ys\n",
    "\n",
    "def Create_dataset(data,embed=None):\n",
    "\n",
    "    Xs,ys= embedding(data,embed)\n",
    "    df = pd.DataFrame(Xs)\n",
    "    df['label'] = list(ys)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoML_result = './AutoML_result_0608/'\n",
    "test_result = './Test3_result/leaderboard_data-07-12-4/'\n",
    "import os \n",
    "if not os.path.exists(test_result):\n",
    "    os.makedirs(test_result)\n",
    "def Test(d =\" test1\"):\n",
    "    embed_types = ['ESM','ProtBert_bfd','ProtBert','T5','UniRep'] #'ESM2_15b'\n",
    "\n",
    "    binary_metric = ['accuracy',\n",
    "                     'mcc',\n",
    "                     'roc_auc',\n",
    "                     'average_precision',\n",
    "                     'precision',\n",
    "                     'recall',\n",
    "                     'log_loss'\n",
    "                    ]\n",
    "    # print(model.evaluate(df, silent=True))\n",
    "    for embed in embed_types:\n",
    "        print(embed)\n",
    "        if d == 'test1':\n",
    "            data = 'test_data1_2023-6-9_15_31.csv'\n",
    "        else:\n",
    "            data = 'test_data2_2023-6-9_15_31.csv'\n",
    "        test_df = Create_dataset(data,embed)\n",
    "        predicter = TabularPredictor.load('{}AutoML_{}_Oversampling/'.format(AutoML_result,embed))\n",
    "        leaderboard = predicter.leaderboard(test_df, extra_metrics = binary_metric,silent=True)\n",
    "        result = predicter.evaluate(test_df,silent=True)\n",
    "        eval_df = pd.DataFrame(result,index=['{}_{}'.format(data.split('.')[0],embed)])\n",
    "        leaderboard.to_csv(\"./{}{}_{}.csv\".format(test_result,data.split('.')[0],embed))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM\n",
      "load test_data1_2023-6-9_15_31.csv esm embedding\n",
      "226\n",
      "(226, 1280)\n",
      "ProtBert_bfd\n",
      "load test_data1_2023-6-9_15_31.csv ProtBert_bfd_embed embedding from ../dataset/dataset2.0/ProtBert_bfd_embed/test_data1_2023-6-9_15_31_embeds.npy\n",
      "226\n",
      "(226, 1024)\n",
      "ProtBert\n",
      "load test_data1_2023-6-9_15_31.csv ProtBert_embed embedding from ../dataset/dataset2.0/ProtBert_embed/test_data1_2023-6-9_15_31_embeds.npy\n",
      "226\n",
      "(226, 1024)\n",
      "T5\n",
      "load test_data1_2023-6-9_15_31.csv T5_embed embedding from ../dataset/dataset2.0/T5_embed/test_data1_2023-6-9_15_31_embeds.npy\n",
      "226\n",
      "(226, 1024)\n",
      "UniRep\n",
      "load test_data1_2023-6-9_15_31.csv UniRep_embed embedding from ../dataset/dataset2.0/UniRep_embed/test_data1_2023-6-9_15_31_embeds.npy\n",
      "226\n",
      "(226, 1900)\n"
     ]
    }
   ],
   "source": [
    "Test(d = 'test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
